{
  "name": "Titouan Galopin",
  "tagline": "Personnal website",
  "body": "# SimHash or the way to compare quickly two datasets\r\n\r\nSimHash is an **algorithm created by Moses Charikar**, from Google. It let us to compare easily\r\ntwo texts and more generally two datasets of any type, quickly and effectively.\r\n\r\nWhat does this really mean? Let's talk a bit about it.\r\n\r\n\r\n### The similarity problem\r\n\r\nComputers are very pragmatic. They can determine very fast whether two elements are different\r\nor not. It's a binary world: equal or different.\r\n\r\nImagine now we would like to have an idea of the similarity between these two elements.\r\nThat would be a much bigger problem: a computer is not designed to do such comparison by nature.\r\nIt's difficult, so it takes resources.\r\n\r\nFor a better understanding, let's take the following sentences as an example:\r\n\r\n``` no-highlight\r\nShakespeare produced most of his known work between 1589 and 1613\r\n```\r\n\r\n``` no-highlight\r\nShakespeare produced most of his work after 1589\r\n```\r\n\r\nHow does the computer will determine if the texts are (strictly) equals? It will\r\nbrowse the first text and compare each letter of it with the letter in the same\r\nposition in the second text.\r\n\r\nBut the point here is that if the computer find a difference, **it stops**. It does not\r\nuse anymore resources, it knows that the strings are strictly different.\r\n\r\nThat's where similarity is a challenge. If we check for strict equality, we only need\r\nto stop on the first difference. If we want a similarity estimation, we have to check\r\nthe entire text. In math it would be:\r\n\r\n$similarity(A, B) = \\frac{A \\cap B}{A \\cup B}$\r\n\r\nFor big datasets, the part $A \\cap B$ is very hard to compute. That's where SimHash is useful.\r\n\r\nWith SimHash, we will create two fingerprints to replace the datasets A and B:\r\n\r\n$simhash(A) \\cap simhash(B)$\r\n\r\nThus we will compare much smaller elements and the comparison time will be dramatically reduced.\r\n\r\n\r\n### SimHash or the way to create fingerprints\r\n\r\nTo compare fingerprints, we need an algorithm that generate them using a big dataset.\r\nThe first idea would be to use hash (md5, sha1), but theses algorithms does not represent\r\nwell a text as if the text change a bit, the hash change a lot.\r\n\r\nSimHash does not behave like this: instead, it's a bit like a very compressed version\r\nof the dataset (it does not change a lot if the text does not change a lot).\r\n\r\nThe official SimHash algorithm is:\r\n\r\n- Define a fingerprint size (for instance 32 bits)\r\n- Create an array `V[]` filled with this size of zeros\r\n- For each element in the dataset, we create a unique hash with md5,\r\n  sha1 of any other hash algorithm that give same-sized results\r\n- For each hash, for each bit `i` in this hash:\r\n    - If the bit is `0`, we add `1` to `V[i]`\r\n    - If the bit is `1`, we take `1` from `V[i]`\r\n- For each bit `j` of the global fingerprint:\r\n    - If `V[j] >= 0`, we set `V[j] = 1`\r\n    - If `V[j] < 0`, we set `V[j] = 0`\r\n    \r\nIt gives us a fingerprint characterizing our text, an approximation of the text data.\r\nThis fingerprint is a binary number, for instance: `10101011100010001010000101111100`.\r\n\r\nNow, to find\r\n\r\n$simhash(A) \\cap simhash(B)$\r\n\r\nwe only have to use a XOR operation:\r\n\r\n``` no-highlight\r\n    10101011100010001010000101111100\r\nXOR 10101011100010011110000101111110\r\n  = 00000000000000010100000000000010\r\n```\r\n\r\nHere, the `1` in the XOR result are the differences between the two fingerprints.\r\nTo get an idea of the difference between the original texts, we just have to count\r\nthe number of `1` and divide it by the total size.\r\n\r\nHere, we have `3` ones for `32` characters : the estimation of the difference is\r\n`3 / 32 = 0,09375`, so the estimation of the similarity is `1 - 3 / 32 = 0,90625`\r\n(a bit more than 90%). We have our similarity index!\r\n\r\n\r\n### Real world usage\r\n\r\nSimHash is currently used by Google to compare page with its database, to avoid duplicate\r\ncontents. But we can use it too!\r\n\r\nI created a small PHP library to use it programmatically in PHP: [SimHashPHP](https://github.com/tgalopin/SimHashPhp).\r\n\r\nBut the main usage of SimHash is to compare things in a database. For instance, let's\r\nimagine we want to find the most similar articles of the one we are currently reading.\r\nIt appears complicated at the first sight using only SQL. However with SimHash it's not\r\nthat difficult: we just have to store a fingerprint for each article, and use the XOR\r\noperation in SQL to count the `1` in the binary result.\r\n\r\nFor instance:\r\n\r\n``` sql\r\nSELECT id, title, (LENGTH(CONV(fp ^ ?, 10, 2)) - LENGTH(REPLACE(CONV(fp ^ ?, 10, 2), '1', ''))) / LENGTH('1') AS comparison\r\nFROM articles\r\nORDER BY comparison ASC\r\n```",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}